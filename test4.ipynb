{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from typing import Optional, Union, Sequence\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "Number = Union[int, float]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _compute_dt(shape, start_points=None, end_points=None):\n",
    "    \"\"\"\n",
    "    Compute uniform spacing (dt) for each dimension based on domain lengths, step sizes,\n",
    "    start points, and end points. Defaults to a unit domain if not specified.\n",
    "\n",
    "    Parameters:\n",
    "    shape (Sequence[int]): The shape of the input excluding batch and channel, i.e. (d_1, d_2, ..., d_n).\n",
    "    step_sizes (Sequence[float], optional): Step sizes for each dimension. Defaults to shape-based uniform spacing.\n",
    "    start_points (Sequence[float], optional): Start points for each dimension. Defaults to 0.0 for all dimensions.\n",
    "    end_points (Sequence[float], optional): End points for each dimension. Defaults to 1.0 for all dimensions.\n",
    "\n",
    "    Returns:\n",
    "    dt_list (Sequence[float]): A list of spacings, one per dimension.\n",
    "    grid (List[torch.Tensor]): A list of grid points for each dimension based on the spacing and domain.\n",
    "    \"\"\"\n",
    "    dim = len(shape)\n",
    "\n",
    "    # Set default start and end points if not provided\n",
    "    if start_points is None:\n",
    "        start_points = torch.zeros(dim).tolist()\n",
    "    if end_points is None:\n",
    "        end_points = torch.ones(dim).tolist()\n",
    "\n",
    "    # Validate that start_points and end_points match the number of dimensions\n",
    "    if len(start_points) != dim or len(end_points) != dim:\n",
    "        raise ValueError(\"Start points and end points must match the number of input dimensions ({dim}).\")\n",
    "\n",
    "    # Compute domain lengths from start and end points\n",
    "    domain_lengths = [end_points[i] - start_points[i] for i in range(dim)]\n",
    "\n",
    "    # Generate grid points for each dimension using torch.linspace\n",
    "    grid = [torch.linspace(start_points[i], end_points[i], steps=shape[i]) for i in range(dim)]\n",
    "\n",
    "    # Compute dt directly from the grid\n",
    "    dt_list = [(grid[i][1] - grid[i][0]).item() for i in range(dim)]\n",
    "\n",
    "    return dt_list, grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralConvLaplace1D(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels, \n",
    "        out_channels, \n",
    "        n_modes,\n",
    "        complex_data=False,\n",
    "        max_n_modes=None,\n",
    "        bias=True,\n",
    "        separable=False,\n",
    "        resolution_scaling_factor: Optional[Union[Number, List[Number]]] = None,\n",
    "        xno_block_precision=\"full\",\n",
    "        rank=0.5,\n",
    "        factorization=None,\n",
    "        implementation=\"reconstructed\",\n",
    "        fixed_rank_modes=False,\n",
    "        decomposition_kwargs: Optional[dict] = None,\n",
    "        init_std=\"auto\",\n",
    "        fft_norm=\"forward\",\n",
    "        device=None, \n",
    "        linspace_steps=None, \n",
    "        linspace_startpoints=None, \n",
    "        linspace_endpoints=None, \n",
    "        \n",
    "        ):\n",
    "        super(SpectralConvLaplace1D, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.linspace_steps = linspace_steps\n",
    "        self.linspace_startpoints = linspace_startpoints\n",
    "        self.linspace_endpoints = linspace_endpoints\n",
    "        \n",
    "        modes = list(n_modes)\n",
    "        self.modes1 = modes[0]\n",
    "        self.scale = (1 / (in_channels*out_channels))\n",
    "        self.weights_pole = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, dtype=torch.cfloat))\n",
    "        self.weights_residue = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, dtype=torch.cfloat))\n",
    "       \n",
    "    def output_PR(self, lambda1,alpha, weights_pole, weights_residue):   \n",
    "        Hw=torch.zeros(weights_residue.shape[0],weights_residue.shape[0],weights_residue.shape[2],lambda1.shape[0], device=alpha.device, dtype=torch.cfloat)\n",
    "        term1=torch.div(1,torch.sub(lambda1,weights_pole))\n",
    "        Hw=weights_residue*term1\n",
    "        output_residue1=torch.einsum(\"bix,xiok->box\", alpha, Hw) \n",
    "        output_residue2=torch.einsum(\"bix,xiok->bok\", alpha, -Hw) \n",
    "        return output_residue1,output_residue2    \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # t=grid_x_train\n",
    "        # #Compute input poles and resudes by FFT\n",
    "        # dt=(t[1]-t[0]).item()\n",
    "        \n",
    "        if self.linspace_steps is None:\n",
    "            self.linspace_steps = x.shape[2:]\n",
    "            \n",
    "        dt_list, shape = _compute_dt(shape=self.linspace_steps, \n",
    "                                     start_points=self.linspace_startpoints, \n",
    "                                     end_points=self.linspace_endpoints)\n",
    "        t = shape[0]\n",
    "        dt = dt_list[0]        \n",
    "        \n",
    "        alpha = torch.fft.fft(x)\n",
    "        lambda0=torch.fft.fftfreq(t.shape[0], dt)*2*np.pi*1j\n",
    "        lambda1=lambda0.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
    "        lambda1=lambda1\n",
    "    \n",
    "        # Obtain output poles and residues for transient part and steady-state part\n",
    "        output_residue1,output_residue2= self.output_PR(lambda1, alpha, self.weights_pole, self.weights_residue)\n",
    "    \n",
    "        # Obtain time histories of transient response and steady-state response\n",
    "        x1 = torch.fft.ifft(output_residue1, n=x.size(-1))\n",
    "        x1 = torch.real(x1)\n",
    "        x2=torch.zeros(output_residue2.shape[0],output_residue2.shape[1],t.shape[0], device=alpha.device, dtype=torch.cfloat)    \n",
    "        term1=torch.einsum(\"bix,kz->bixz\", self.weights_pole, t.type(torch.complex64).reshape(1,-1))\n",
    "        term2=torch.exp(term1) \n",
    "        x2=torch.einsum(\"bix,ioxz->boz\", output_residue2,term2)\n",
    "        x2=torch.real(x2)\n",
    "        x2=x2/x.size(-1)\n",
    "        return x1+x2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dimensions = (20, 4, 2048)\n",
    "input = torch.rand(*n_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace = SpectralConvLaplace1D(\n",
    "    in_channels=4, \n",
    "    out_channels=4, \n",
    "    n_modes=(1,)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 4, 2048])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = nn.InstanceNorm2d(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sina/Documents/GitHub_Local/XNO/.venv/lib/python3.11/site-packages/torch/nn/modules/instancenorm.py:115: UserWarning: input's size at dim=0 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 4, 2048])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 4, 2048])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(laplace(norm(input))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_modes1 = 16\n",
    "max_modes2 = 16\n",
    "in_channels = 4\n",
    "out_channels = 4\n",
    "n_modes= (2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 1 / (in_channels * out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_modes = max_modes1 + max_modes2 + (max_modes1 * max_modes2)\n",
    "weight = nn.Parameter(\n",
    "    scale * torch.rand(in_channels, out_channels, total_modes, dtype=torch.cfloat)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 288])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes1, modes2 = n_modes\n",
    "start_pole1 = 0\n",
    "end_pole1 = modes1\n",
    "start_pole2 = end_pole1\n",
    "end_pole2 = start_pole2 + modes2\n",
    "start_residue = end_pole2\n",
    "end_residue = start_residue + (modes1 * modes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 4, 2]), torch.Size([4, 4, 2]), torch.Size([4, 4, 2, 2]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_pole1 = weight[:, :, start_pole1:end_pole1].view(weight.size(0), weight.size(1), modes1)\n",
    "weights_pole2 = weight[:, :, start_pole2:end_pole2].view(weight.size(0), weight.size(1), modes2)\n",
    "weights_residue = weight[:, :, start_residue:end_residue].view(weight.size(0), weight.size(1), modes1, modes2)\n",
    "\n",
    "weights_pole1.shape, weights_pole2.shape, weights_residue.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 4, 2]), torch.Size([4, 4, 2]), torch.Size([4, 4, 2, 2]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_pole1 = nn.Parameter(scale * torch.rand(in_channels, out_channels, modes1,  dtype=torch.cfloat))\n",
    "weights_pole2 = nn.Parameter(scale * torch.rand(in_channels, out_channels, modes2, dtype=torch.cfloat))\n",
    "weights_residue = nn.Parameter(scale * torch.rand(in_channels, out_channels, modes1,  modes2, dtype=torch.cfloat))\n",
    "\n",
    "weights_pole1.shape, weights_pole2.shape, weights_residue.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
